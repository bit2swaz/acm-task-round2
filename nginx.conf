# Worker connections define how many simultaneous users we can handle.
events { worker_connections 1024; } 

http {
    # UPSTREAM: This creates a "Pool" of servers.
    # Think of this as defining a variable "my_backend_pool".
    upstream my_backend_pool {
        # WEIGHT: This controls the A/B split ratio.
        # weight=1 on both means 50/50 split.
        # If we wanted a "Canary Release" (90% old, 10% new), we would do:
        # server app-a weight=9;
        # server app-b weight=1;
        
        server app-a:5678 weight=1;
        server app-b:5678 weight=1;
    }

    server {
        listen 80;

        location / {
            # PROXY_PASS: The command that actually forwards the traffic.
            # We point it to our upstream pool name.
            proxy_pass http://my_backend_pool;
            
            # HEADERS: Good citizenship. 
            # Since Nginx is the one talking to the App, the App thinks the request came from Nginx.
            # We add these headers to tell the App the *Real* IP of the user.
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}